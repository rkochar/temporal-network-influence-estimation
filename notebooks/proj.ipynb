{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ipywidgets import widgets\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# dataset = 'infectious'\n",
    "# beta = 1\n",
    "# Delta_T = 0.1 # Fraction of dataset to select (this is then divided by phi)\n",
    "# k = 10\n",
    "# phi = 0.1\n",
    "# lines = 0\n",
    "# runs = 3\n",
    "\n",
    "def get_data(dataset, Delta_T, phi):\n",
    "    lines = 0\n",
    "    if dataset == \"infectious\":\n",
    "        lines = 17298\n",
    "    elif dataset == \"ht09_contact\":\n",
    "        lines = 20818\n",
    "    elif dataset == \"SFHH\":\n",
    "        lines = 70261\n",
    "    elif dataset == \"tij\":\n",
    "        lines = 78249\n",
    "\n",
    "    total_edges = int(lines * Delta_T)\n",
    "    random_start_point = np.random.uniform(0, float(1 - Delta_T))\n",
    "    start = int(lines * random_start_point)\n",
    "\n",
    "    train_lines = int(total_edges * float(1 - phi))\n",
    "    mid = start + train_lines\n",
    "    end = start + total_edges\n",
    "\n",
    "    print(f'Total lines: {total_edges}, train lines {train_lines}')\n",
    "    print(f'Starting at {start} till {mid} to predict till {end}')\n",
    "\n",
    "    path_to_file = f'../data/{dataset}.txt'\n",
    "\n",
    "    all_data = np.loadtxt(path_to_file, delimiter='\\t', dtype=int)[start: end]\n",
    "    train_data = all_data[:train_lines]\n",
    "    predict_data = all_data[mid:]\n",
    "\n",
    "    return all_data, train_data, predict_data, train_lines, total_edges, start, mid, end\n",
    "\n",
    "# Check all edges are unique\n",
    "\n",
    "# a = np.array([src, dst, ts])\n",
    "# a = a.T\n",
    "# # np.any(np.all(np.unique(a, axis=1) == a, axis=1))\n",
    "# u, c = np.unique(a, return_counts=True, axis=0)\n",
    "# u[c > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Graph\n",
    "def make_graph(all_data):\n",
    "    src, dst, ts = [], [], []\n",
    "    graph = nx.MultiGraph()\n",
    "\n",
    "    for line in all_data:\n",
    "        src.append(line[0])\n",
    "        dst.append(line[1])\n",
    "        ts.append(line[2])\n",
    "\n",
    "        if graph.nodes.get(line[0]) is None:\n",
    "            graph.add_node(line[0], is_infected=False, infected_at=math.inf, influence=-1, influences=None, pred=None, polyfit_prediction=None)\n",
    "        if graph.nodes.get(line[1]) is None:\n",
    "            graph.add_node(line[1], is_infected=False, infected_at=math.inf, influence=-1, influences=None, pred=None, polyfit_prediction=None)\n",
    "\n",
    "        graph.add_edge(line[0], line[1], key=line[2], timestamp=line[2])\n",
    "\n",
    "    src, dst, ts = np.array(src), np.array(dst), np.array(ts) # ts is given sorted\n",
    "    print(graph.nodes.get(src[0]))\n",
    "\n",
    "    return src, dst, ts, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_edge(edge, g, inf, ins, beta):\n",
    "    # TODO: use beta\n",
    "    if g.nodes.get(edge[0])['is_infected'] and edge[2] > g.nodes.get(edge[0])['infected_at'] and not g.nodes.get(edge[1])['is_infected']:\n",
    "        inf += 1\n",
    "        g.nodes.get(edge[1])['in_infected'] = True\n",
    "        g.nodes.get(edge[1])['infected_at'] = edge[2]\n",
    "        ins[str(edge[2])] = ins.get(str(edge[2]), 0) + 1\n",
    "    \n",
    "    return inf, ins, g\n",
    "\n",
    "def find_influence_of_node(edges, node, at, train_lines, beta):\n",
    "    g = nx.Graph()\n",
    "    influence, influences, pred = 0, {}, {}\n",
    "    \n",
    "    for edge in edges:\n",
    "        if g.nodes.get(edge[0]) is None:\n",
    "            g.add_node(edge[0], is_infected=False, infected_at=math.inf)\n",
    "        if g.nodes.get(edge[1]) is None:\n",
    "            g.add_node(edge[1], is_infected=False, infected_at=math.inf)\n",
    "\n",
    "    g.nodes.get(node)['is_infected'] = True\n",
    "    g.nodes.get(node)['infected_at'] = at\n",
    "\n",
    "    # TODO: Check influence. I think it's getting unset somewhere because of how Python handles pointers.\n",
    "    for i, edge in enumerate(edges):\n",
    "        if i <= train_lines:\n",
    "            influence, influences, g = check_edge(edge, g, influence, influences, beta)\n",
    "            new_edge = (edge[1], edge[0], edge[2])\n",
    "            influence, influences, g = check_edge(new_edge, g, influence, influences, beta)\n",
    "        else:\n",
    "            influence, pred, g = check_edge(edge, g, influence, pred, beta)\n",
    "            new_edge = (edge[1], edge[0], edge[2])\n",
    "            influence, pred, g = check_edge(new_edge, g, influence, pred, beta)\n",
    "                \n",
    "    return influence, influences, pred\n",
    "\n",
    "# TODO: Fix this\n",
    "def find_influence_in_graph(graph, all_data, train_lines, beta):\n",
    "    for i, edge in enumerate(all_data):\n",
    "        for e in [edge[0], edge[1]]:\n",
    "            if graph.nodes.get(e)['influence'] == -1:\n",
    "                z, zz, zzz = find_influence_of_node(all_data, e, edge[2], train_lines, beta)\n",
    "                # print(f'z: {z}, zz: {zz}, zzz: {zzz}')\n",
    "                graph.nodes.get(e)['influence'] = z\n",
    "                graph.nodes.get(e)['influences'] = zz\n",
    "                if zzz is not {}:\n",
    "                    graph.nodes.get(e)['pred'] = zzz # time series of influence. [(0, 0), (1, 5), (2, 10), (4, 12)]\n",
    "\n",
    "    most_influential_nodes = sorted(list(graph.nodes.data(\"influence\")), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(most_influential_nodes)\n",
    "    return most_influential_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyfit(data, new_points, dimension):\n",
    "#     print(f'data: {data}')\n",
    "    k, v = list(map(lambda x: int(x), data.keys())), list(data.values())\n",
    "#     print(f'keys: {k}')\n",
    "    print(f'values: {v}')\n",
    "    \n",
    "    fit = np.polyfit(k, v, 1) #The use of 1 signifies a linear fit.\n",
    "\n",
    "    line = np.poly1d(fit)\n",
    "    new_points = np.arange(new_points) + (k[-1] + 1)\n",
    "    new_p = line(new_points)\n",
    "    print(f'New points predicted are: {new_p}')\n",
    "\n",
    "    return new_p\n",
    "#     return np.cumsum(line(new_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for dataset infectious with delta_t 0.1 and phi 0.1 and beta 1\n",
      "Total lines: 1729, train lines 1556\n",
      "Starting at 12948 till 14504 to predict till 14677\n",
      "{'is_infected': False, 'infected_at': inf, 'influence': -1, 'influences': None, 'pred': None, 'polyfit_prediction': None}\n",
      "[(297, 114), (266, 100), (296, 82), (230, 69), (292, 66)]\n",
      "values: [4, 2, 1, 1, 3, 2, 3, 2, 4, 3, 4, 3, 2, 4, 4, 3, 2, 2, 2, 3, 1, 3, 2, 1, 2, 3, 4, 2, 2, 1, 2, 2, 2, 1, 1, 3, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 3, 2, 2, 1]\n",
      "New points predicted are: [1.80355115 1.78756294 1.77157472 1.7555865  1.73959829]\n",
      "values: [2, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 2, 3, 2, 2, 1, 3, 3, 3, 2, 2, 1, 1, 2, 1, 2, 1, 1, 3, 2, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1]\n",
      "New points predicted are: [1.2740922  1.27075226 1.26741232 1.26407238 1.26073243]\n",
      "values: [1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 3, 4, 3, 3, 4, 2, 2, 3, 3, 4, 3, 3, 2, 1, 2, 1, 3, 3, 2, 2, 3, 2, 2, 3, 4, 1, 1]\n",
      "New points predicted are: [2.53741222 2.5459682  2.55452417 2.56308015 2.57163613]\n",
      "values: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1]\n",
      "New points predicted are: [1.3363808  1.34065296 1.34492512 1.34919728 1.35346945]\n",
      "values: [1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 3, 3, 2, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1, 3, 4, 1, 1, 2, 2, 2, 3, 2, 1]\n",
      "New points predicted are: [2.05370647 2.06958951 2.08547255 2.10135559 2.11723863]\n"
     ]
    }
   ],
   "source": [
    "# Find k most influential nodes\n",
    "def simulate(dataset, delta_t, phi, beta):\n",
    "    print(f'Running simulation for dataset {dataset} with delta_t {delta_t} and phi {phi} and beta {beta}')\n",
    "    all_data, train_data, predict_data, train_lines, total_edges, start, mid, end = get_data(dataset, delta_t, phi)\n",
    "    src, dst, ts, graph = make_graph(all_data)\n",
    "    most_influential_nodes = find_influence_in_graph(graph, all_data, train_lines, beta) # 5 most influential nodes [(node id, influence)]\n",
    "\n",
    "    for node in most_influential_nodes:\n",
    "        thisnode = graph.nodes.get(node[0])\n",
    "        if thisnode is not {}:\n",
    "            thisnode['polyfit_prediction'] = polyfit(thisnode['influences'], new_points=5, dimension=1)\n",
    "        \n",
    "simulate(\"infectious\", 0.1, 0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081767150cae448a9600b7fe3b170513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='infectious', description='dataset'), FloatSlider(value=0.1, description='del…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dropdown = widgets.Dropdown(options=['infectious', 'ht09_contact', 'SFHH', 'tij_InVS15'], description='Dataset', disabled=False, continuous_update=True)\n",
    "phi_slider = widgets.FloatSlider(min=0.1, max=0.9, step=0.01, value=0.1, continuous_update=True)\n",
    "delta_t_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.1, continuous_update=True)\n",
    "beta_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.75, continuous_update=True)\n",
    "\n",
    "w = widgets.interactive(simulate, dataset=dataset_dropdown.value, delta_t=delta_t_slider.value, phi=phi_slider.value, beta=beta_slider.value)\n",
    "display(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot real influence with predicted influence\n",
    "# Minimize on MSE or MAE or any other distance metric to find best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_slider = widgets.IntSliderWidget(min=-5, max=5, step=1, value=0)\n",
    "# b_slider = widgets.FloatSliderWidget(min=-5, max=5, step=0.3, value=0)\n",
    "#w = widgets.interactive(sigmoid_demo,a=a_slider, b=b_slider)\n",
    "#display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bor = 'A'\n",
    "# drop_down = widgets.Dropdown(options=['A','B','C','D'],\n",
    "#                              description='Choose',\n",
    "#                              disabled=False)\n",
    "#\n",
    "# def dropdown_handler(change):\n",
    "#     global bor\n",
    "#     print(change.new)\n",
    "#     bor = change.new  # This line isn't working\n",
    "# drop_down.observe(dropdown_handler, names='value')\n",
    "# display(drop_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e35c14a8caca76198b34fb255762891fb38351c0ec24f1fa8546521f6a1a9596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
