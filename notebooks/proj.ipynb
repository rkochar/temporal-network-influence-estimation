{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ipywidgets import widgets\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# dataset = 'infectious'\n",
    "# beta = 1\n",
    "# Delta_T = 0.1 # Fraction of dataset to select (this is then divided by phi)\n",
    "# k = 10\n",
    "# phi = 0.1\n",
    "# lines = 0\n",
    "# runs = 3\n",
    "\n",
    "def get_data(dataset, Delta_T, phi):\n",
    "    lines = 0\n",
    "    if dataset == \"infectious\":\n",
    "        lines = 17298\n",
    "    elif dataset == \"ht09_contact\":\n",
    "        lines = 20818\n",
    "    elif dataset == \"SFHH\":\n",
    "        lines = 70261\n",
    "    elif dataset == \"tij\":\n",
    "        lines = 78249\n",
    "\n",
    "    total_edges = int(lines * Delta_T)\n",
    "    random_start_point = np.random.uniform(0, float(1 - Delta_T))\n",
    "    start = int(lines * random_start_point)\n",
    "\n",
    "    train_lines = int(total_edges * float(1 - phi))\n",
    "    mid = start + train_lines\n",
    "    end = start + total_edges\n",
    "\n",
    "    print(f'Total lines: {total_edges}, train lines {train_lines}')\n",
    "    print(f'Starting at {start} till {mid} to predict till {end}')\n",
    "\n",
    "    path_to_file = f'../data/{dataset}.txt'\n",
    "\n",
    "    all_data = np.loadtxt(path_to_file, delimiter='\\t', dtype=int)[start: end]\n",
    "    train_data = all_data[:train_lines]\n",
    "    predict_data = all_data[train_lines:]\n",
    "    new_points = predict_data[-1][2] - predict_data[0][2] + 1\n",
    "    print(f'Starting at {train_data[0]} till {predict_data[0]} to predict till {predict_data[-1]}')\n",
    "\n",
    "\n",
    "    return all_data, train_data, predict_data, train_lines, total_edges, start, mid, end, new_points\n",
    "\n",
    "# Check all edges are unique\n",
    "\n",
    "# a = np.array([src, dst, ts])\n",
    "# a = a.T\n",
    "# # np.any(np.all(np.unique(a, axis=1) == a, axis=1))\n",
    "# u, c = np.unique(a, return_counts=True, axis=0)\n",
    "# u[c > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Graph\n",
    "def make_graph(all_data):\n",
    "    src, dst, ts = [], [], []\n",
    "    graph = nx.MultiGraph()\n",
    "\n",
    "    for line in all_data:\n",
    "        src.append(line[0])\n",
    "        dst.append(line[1])\n",
    "        ts.append(line[2])\n",
    "\n",
    "        if graph.nodes.get(line[0]) is None:\n",
    "            graph.add_node(line[0], is_infected=False, infected_at=math.inf, influence=-1, influences=None, pred=None, polyfit_prediction=None)\n",
    "        if graph.nodes.get(line[1]) is None:\n",
    "            graph.add_node(line[1], is_infected=False, infected_at=math.inf, influence=-1, influences=None, pred=None, polyfit_prediction=None)\n",
    "\n",
    "        graph.add_edge(line[0], line[1], key=line[2], timestamp=line[2])\n",
    "\n",
    "    src, dst, ts = np.array(src), np.array(dst), np.array(ts) # ts is given sorted\n",
    "\n",
    "    return src, dst, ts, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes_timestamps(start, mid, end, influences):\n",
    "    xs, ys = [], []\n",
    "    for i in range(start, end + 1):\n",
    "        if i < mid:\n",
    "            xs.append((i, influences.get(str(i), 0)))\n",
    "        else:\n",
    "            ys.append((i, influences.get(str(i), 0)))\n",
    "            \n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_edge(edge, g, inf, ins, beta):\n",
    "    if g.nodes.get(edge[0])['is_infected'] and edge[2] > g.nodes.get(edge[0])['infected_at'] and not g.nodes.get(edge[1])['is_infected'] and np.random.random() <= beta:\n",
    "        inf += 1\n",
    "        g.nodes.get(edge[1])['in_infected'] = True\n",
    "        g.nodes.get(edge[1])['infected_at'] = edge[2]\n",
    "        ins[str(edge[2])] = ins.get(str(edge[2]), 0) + 1\n",
    "    \n",
    "    return inf, ins, g\n",
    "\n",
    "def find_influence_of_node(edges, node, at, beta):\n",
    "    g = nx.Graph()\n",
    "    influence, influences, pred = 0, {}, {}\n",
    "    \n",
    "    for edge in edges:\n",
    "        if g.nodes.get(edge[0]) is None:\n",
    "            g.add_node(edge[0], is_infected=False, infected_at=math.inf)\n",
    "        if g.nodes.get(edge[1]) is None:\n",
    "            g.add_node(edge[1], is_infected=False, infected_at=math.inf)\n",
    "\n",
    "    g.nodes.get(node)['is_infected'] = True\n",
    "    g.nodes.get(node)['infected_at'] = at\n",
    "\n",
    "    # TODO: Check influence. I think it's getting unset somewhere because of how Python handles pointers.\n",
    "    for i, edge in enumerate(edges):\n",
    "        influence, influences, g = check_edge(edge, g, influence, influences, beta)\n",
    "        new_edge = (edge[1], edge[0], edge[2])\n",
    "        influence, influences, g = check_edge(new_edge, g, influence, influences, beta)\n",
    "        \n",
    "    return influence, influences\n",
    "\n",
    "# TODO: Fix this\n",
    "def find_influence_in_graph(graph, all_data, beta):\n",
    "    for i, edge in enumerate(all_data):\n",
    "        for e in [edge[0], edge[1]]:\n",
    "            if graph.nodes.get(e)['influence'] == -1:\n",
    "                z, zz = find_influence_of_node(all_data, e, edge[2], beta)\n",
    "                graph.nodes.get(e)['influence'] = z\n",
    "                graph.nodes.get(e)['influences'] = zz\n",
    "\n",
    "    most_influential_nodes = sorted(list(graph.nodes.data(\"influence\")), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"most influentual nodes: {most_influential_nodes}\")\n",
    "    return most_influential_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyfit(data, new_points, dimension):\n",
    "    print(f\"new_points: {new_points}\")\n",
    "    data = np.array(list(map(lambda x: [x[0], x[1]], data)))\n",
    "    fit = np.polyfit(data[:, 0], data[:, 1], 1) # The use of 1 signifies a linear fit.\n",
    "\n",
    "    line = np.poly1d(fit)\n",
    "    new_points = np.arange(new_points) + (data[-1][0] + 1)\n",
    "    return np.cumsum(line(new_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(most_influential_nodes, graph):\n",
    "    clr = ['r', 'g', 'b', 'y', 'm']\n",
    "\n",
    "    for i, node in enumerate(most_influential_nodes):\n",
    "        y_true = graph.nodes.get(node[0])['pred']\n",
    "        y_pred = graph.nodes.get(node[0])['polyfit_prediction']\n",
    "        ts = list(map(lambda x: x[0], y_true))\n",
    "        print(f\"y_pred: {y_pred}\")\n",
    "        print(f\"y_true: {y_true}\")\n",
    "        print(f\"y_pred_len: {len(y_pred)}\")\n",
    "        print(f\"y_true_len: {len(y_true)}\")\n",
    "        plt.plot(ts, np.cumsum(list(map(lambda x: x[1], y_true))), 'o', color=clr[i])\n",
    "        plt.plot(ts, y_pred, '-', color=clr[i])\n",
    "\n",
    "    # save the plot\n",
    "    plot_name = 's.png'\n",
    "    plt.savefig(plot_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(dataset, delta_t, phi, beta):\n",
    "    print(f'Running simulation for dataset {dataset} with delta_t {delta_t} and phi {phi} and beta {beta}')\n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "        flag = False \n",
    "        all_data, train_data, predict_data, train_lines, total_edges, start, mid, end, new_points = get_data(dataset, delta_t, phi)\n",
    "        src, dst, ts, graph = make_graph(all_data)\n",
    "        most_influential_nodes = find_influence_in_graph(graph, all_data, beta) # 5 most influential nodes [(node id, influence)]\n",
    "        \n",
    "        for node in most_influential_nodes:\n",
    "            thisnode = graph.nodes.get(node[0])\n",
    "            if thisnode is not {}:\n",
    "                print(f\"node: {node[0]}\")\n",
    "                thisnode['influences'], thisnode['pred'] = fill_holes_timestamps(train_data[0][2], \\\n",
    "                                                                                 predict_data[0][2], \\\n",
    "                                                                                 predict_data[-1][2], \\\n",
    "                                                                                 thisnode['influences'])\n",
    "                if len(thisnode['pred']) > 3:\n",
    "                    thisnode['polyfit_prediction'] = polyfit(thisnode['influences'], new_points=new_points, dimension=1)\n",
    "\n",
    "        \n",
    "        for node in most_influential_nodes:\n",
    "            if not bool(graph.nodes.get(node[0])['pred']):\n",
    "                flag = True\n",
    "\n",
    "    plot(most_influential_nodes, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate(\"infectious\", 0.1, 0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dropdown = widgets.Dropdown(options=['infectious', 'ht09_contact', 'SFHH', 'tij_InVS15'], description='Dataset', disabled=False, continuous_update=True)\n",
    "phi_slider = widgets.FloatSlider(min=0.1, max=0.9, step=0.01, value=0.1, continuous_update=True)\n",
    "delta_t_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.1, continuous_update=True)\n",
    "beta_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.75, continuous_update=True)\n",
    "\n",
    "w = widgets.interactive(simulate, dataset=dataset_dropdown.value, delta_t=delta_t_slider.value, phi=phi_slider.value, beta=beta_slider.value)\n",
    "display(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e35c14a8caca76198b34fb255762891fb38351c0ec24f1fa8546521f6a1a9596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
