{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ipywidgets import widgets\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# dataset = 'infectious'\n",
    "# beta = 1\n",
    "# Delta_T = 0.1 # Fraction of dataset to select (this is then divided by phi)\n",
    "# k = 10\n",
    "# phi = 0.1\n",
    "# lines = 0\n",
    "# runs = 3\n",
    "\n",
    "def get_data(dataset, Delta_T, phi):\n",
    "    lines = 0\n",
    "    if dataset == \"infectious\":\n",
    "        lines = 17298\n",
    "    elif dataset == \"ht09_contact\":\n",
    "        lines = 20818\n",
    "    elif dataset == \"SFHH\":\n",
    "        lines = 70261\n",
    "    elif dataset == \"tij\":\n",
    "        lines = 78249\n",
    "\n",
    "    total_edges = int(lines * Delta_T)\n",
    "    random_start_point = np.random.uniform(0, float(1 - Delta_T))\n",
    "    start = int(lines * random_start_point)\n",
    "\n",
    "    train_lines = int(total_edges * float(1 - phi))\n",
    "    mid = start + train_lines\n",
    "    end = start + total_edges\n",
    "\n",
    "    print(f'Total lines: {total_edges}, train lines {train_lines}')\n",
    "    print(f'Starting at {start} till {mid} to predict till {end}')\n",
    "\n",
    "    path_to_file = f'../data/{dataset}.txt'\n",
    "\n",
    "    all_data = np.loadtxt(path_to_file, delimiter='\\t', dtype=int)[start: end]\n",
    "    train_data = all_data[:train_lines]\n",
    "    predict_data = all_data[train_lines:]\n",
    "    print(f'Starting at {train_data[0]} till {predict_data[0]} to predict till {predict_data[-1]}')\n",
    "\n",
    "\n",
    "    return all_data, train_data, predict_data, train_lines, total_edges, start, mid, end\n",
    "\n",
    "# Check all edges are unique\n",
    "\n",
    "# a = np.array([src, dst, ts])\n",
    "# a = a.T\n",
    "# # np.any(np.all(np.unique(a, axis=1) == a, axis=1))\n",
    "# u, c = np.unique(a, return_counts=True, axis=0)\n",
    "# u[c > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Graph\n",
    "def make_graph(all_data):\n",
    "    src, dst, ts = [], [], []\n",
    "    graph = nx.MultiGraph()\n",
    "\n",
    "    for line in all_data:\n",
    "        src.append(line[0])\n",
    "        dst.append(line[1])\n",
    "        ts.append(line[2])\n",
    "\n",
    "        if graph.nodes.get(line[0]) is None:\n",
    "            graph.add_node(line[0], is_infected=False, infected_at=math.inf, influence=-1, influences=None, pred=None, polyfit_prediction=None)\n",
    "        if graph.nodes.get(line[1]) is None:\n",
    "            graph.add_node(line[1], is_infected=False, infected_at=math.inf, influence=-1, influences=None, pred=None, polyfit_prediction=None)\n",
    "\n",
    "        graph.add_edge(line[0], line[1], key=line[2], timestamp=line[2])\n",
    "\n",
    "    src, dst, ts = np.array(src), np.array(dst), np.array(ts) # ts is given sorted\n",
    "#     print(graph.nodes.get(src[0]))\n",
    "\n",
    "    return src, dst, ts, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes_timestamps(start, mid, end, influences):\n",
    "    xs, ys = [], []\n",
    "    for i in range(start, end + 1):\n",
    "        if i < mid:\n",
    "            xs.append((i, influences.get(str(i), 0)))\n",
    "        else:\n",
    "            ys.append((i, influences.get(str(i), 0)))\n",
    "            \n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_edge(edge, g, inf, ins, beta):\n",
    "    # TODO: use beta\n",
    "    if g.nodes.get(edge[0])['is_infected'] and edge[2] > g.nodes.get(edge[0])['infected_at'] and not g.nodes.get(edge[1])['is_infected'] and np.random.random() <= beta:\n",
    "        inf += 1\n",
    "        g.nodes.get(edge[1])['in_infected'] = True\n",
    "        g.nodes.get(edge[1])['infected_at'] = edge[2]\n",
    "        ins[str(edge[2])] = ins.get(str(edge[2]), 0) + 1\n",
    "    \n",
    "    return inf, ins, g\n",
    "\n",
    "def find_influence_of_node(edges, node, at, beta):\n",
    "    g = nx.Graph()\n",
    "    influence, influences, pred = 0, {}, {}\n",
    "    \n",
    "    for edge in edges:\n",
    "        if g.nodes.get(edge[0]) is None:\n",
    "            g.add_node(edge[0], is_infected=False, infected_at=math.inf)\n",
    "        if g.nodes.get(edge[1]) is None:\n",
    "            g.add_node(edge[1], is_infected=False, infected_at=math.inf)\n",
    "\n",
    "    g.nodes.get(node)['is_infected'] = True\n",
    "    g.nodes.get(node)['infected_at'] = at\n",
    "\n",
    "    # TODO: Check influence. I think it's getting unset somewhere because of how Python handles pointers.\n",
    "    for i, edge in enumerate(edges):\n",
    "        influence, influences, g = check_edge(edge, g, influence, influences, beta)\n",
    "        new_edge = (edge[1], edge[0], edge[2])\n",
    "        influence, influences, g = check_edge(new_edge, g, influence, influences, beta)\n",
    "        \n",
    "    return influence, influences\n",
    "\n",
    "# TODO: Fix this\n",
    "def find_influence_in_graph(graph, all_data, beta):\n",
    "    for i, edge in enumerate(all_data):\n",
    "        for e in [edge[0], edge[1]]:\n",
    "            if graph.nodes.get(e)['influence'] == -1:\n",
    "                z, zz = find_influence_of_node(all_data, e, edge[2], beta)\n",
    "                graph.nodes.get(e)['influence'] = z\n",
    "                graph.nodes.get(e)['influences'] = zz\n",
    "\n",
    "    most_influential_nodes = sorted(list(graph.nodes.data(\"influence\")), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"most influentual nodes: {most_influential_nodes}\")\n",
    "    return most_influential_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyfit(data, new_points, dimension):\n",
    "    print(f\"new_points: {new_points}\")\n",
    "    k, v = list(map(lambda x: int(x), data.keys())), list(data.values())\n",
    "    print(f\"k: {len(k)}\")\n",
    "    print(f\"v: {len(v)}\")\n",
    "    \n",
    "    fit = np.polyfit(k, v, 1) # The use of 1 signifies a linear fit.\n",
    "\n",
    "    line = np.poly1d(fit)\n",
    "    new_points = np.arange(new_points) + (k[-1] + 1)\n",
    "    new_p = line(new_points)\n",
    "    print(f'New points predicted are: {len(new_p)}')\n",
    "\n",
    "    return new_p\n",
    "#     return np.cumsum(line(new_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(most_influential_nodes, graph):\n",
    "    clr = ['r', 'g', 'b', 'y', 'm']\n",
    "\n",
    "    for i, node in enumerate(most_influential_nodes):\n",
    "        plt.plot(list(graph.nodes.get(node[0])['pred'].keys()), list(graph.nodes.get(node[0])['pred'].values()), 'o', color=clr[i])\n",
    "        #plt.plot(list(graph.nodes.get(node[0])['polyfit_prediction'].keys()), list(graph.nodes.get(node[0])['polyfit_prediction'].values()), 'o')\n",
    "#         print(graph.nodes.get(node[0])['pred'])\n",
    "    # save the plot\n",
    "    plot_name = 's.png'\n",
    "    plt.savefig(plot_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(dataset, delta_t, phi, beta):\n",
    "    print(f'Running simulation for dataset {dataset} with delta_t {delta_t} and phi {phi} and beta {beta}')\n",
    "    flag = True\n",
    "\n",
    "    while flag:\n",
    "        flag = False \n",
    "        all_data, train_data, predict_data, train_lines, total_edges, start, mid, end = get_data(dataset, delta_t, phi)\n",
    "        src, dst, ts, graph = make_graph(all_data)\n",
    "        most_influential_nodes = find_influence_in_graph(graph, all_data, beta) # 5 most influential nodes [(node id, influence)]\n",
    "        \n",
    "        for node in most_influential_nodes:\n",
    "            thisnode = graph.nodes.get(node[0])\n",
    "            if thisnode is not {}:\n",
    "                print(f\"node: {node[0]}\")\n",
    "                thisnode['influences'], thisnode['pred'] = fill_holes_timestamps(train_data[0][2], \\\n",
    "                                                                                 predict_data[0][2], \\\n",
    "                                                                                 predict_data[-1][2], \\\n",
    "                                                                                 thisnode['influences'])\n",
    "                print(f\"preds: {thisnode['pred']}\\n\\n\")\n",
    "                if len(thisnode['pred']) > 3:\n",
    "                    thisnode['polyfit_prediction'] = polyfit(thisnode['influences'], new_points=end - mid, dimension=1)\n",
    "\n",
    "        \n",
    "        for node in most_influential_nodes:\n",
    "            if not bool(graph.nodes.get(node[0])['pred']):\n",
    "                flag = True\n",
    "\n",
    "    # Find all the unique keys in most_influential_nodes\n",
    "    keys_pred = set()\n",
    "    keys_polyfit = set()\n",
    "    for node in most_influential_nodes:\n",
    "        keys_pred.update(graph.nodes.get(node[0])['pred'].keys())\n",
    "        keys_polyfit.update(graph.nodes.get(node[0])['polyfit_prediction'].keys())\n",
    "    \n",
    "    # if a node is missing a key, add it and set it to 0\n",
    "    for node in most_influential_nodes:\n",
    "        for key in keys_pred:\n",
    "            if key not in graph.nodes.get(node[0])['pred']:\n",
    "                graph.nodes.get(node[0])['pred'][key] = 0\n",
    "        for key in keys_polyfit:\n",
    "            if key not in graph.nodes.get(node[0])['polyfit_prediction']:\n",
    "                graph.nodes.get(node[0])['polyfit_prediction'][key] = 0\n",
    "                \n",
    "    # for each node sort keys\n",
    "    for node in most_influential_nodes:\n",
    "        graph.nodes.get(node[0])['pred'] = dict(sorted(graph.nodes.get(node[0])['pred'].items(), key=lambda item: item[0]))\n",
    "        graph.nodes.get(node[0])['polyfit_prediction'] = dict(sorted(graph.nodes.get(node[0])['polyfit_prediction'].items(), key=lambda item: item[0]))\n",
    "\n",
    "    plot(most_influential_nodes, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for dataset infectious with delta_t 0.1 and phi 0.1 and beta 1\n",
      "Total lines: 1729, train lines 1556\n",
      "Starting at 15565 till 17121 to predict till 17294\n",
      "Starting at [ 356  357 1069] till [ 367  396 1346] to predict till [ 399  403 1422]\n",
      "most influentual nodes: [(386, 204), (387, 198), (375, 144), (378, 142), (374, 139)]\n",
      "node: 386\n",
      "preds: [(1346, 1), (1347, 1), (1348, 1), (1349, 1), (1350, 1), (1351, 2), (1352, 1), (1353, 1), (1354, 0), (1355, 0), (1356, 0), (1357, 0), (1358, 1), (1359, 1), (1360, 1), (1361, 0), (1362, 0), (1363, 1), (1364, 1), (1365, 0), (1366, 1), (1367, 0), (1368, 0), (1369, 0), (1370, 0), (1371, 0), (1372, 0), (1373, 0), (1374, 0), (1375, 0), (1376, 0), (1377, 0), (1378, 0), (1379, 0), (1380, 0), (1381, 0), (1382, 0), (1383, 0), (1384, 0), (1385, 0), (1386, 0), (1387, 0), (1388, 0), (1389, 0), (1390, 0), (1391, 0), (1392, 0), (1393, 0), (1394, 0), (1395, 0), (1396, 0), (1397, 0), (1398, 0), (1399, 0), (1400, 0), (1401, 0), (1402, 0), (1403, 0), (1404, 0), (1405, 0), (1406, 0), (1407, 0), (1408, 0), (1409, 0), (1410, 0), (1411, 0), (1412, 0), (1413, 0), (1414, 0), (1415, 0), (1416, 0), (1417, 0), (1418, 0), (1419, 0), (1420, 0), (1421, 0), (1422, 0)]\n",
      "\n",
      "\n",
      "new_points: 173\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfectious\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 21\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(dataset, delta_t, phi, beta)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthisnode[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(thisnode[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m             thisnode[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolyfit_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpolyfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthisnode\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfluences\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m most_influential_nodes:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(graph\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mget(node[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m, in \u001b[0;36mpolyfit\u001b[0;34m(data, new_points, dimension)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolyfit\u001b[39m(data, new_points, dimension):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_points: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_points\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x), \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())), \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(k)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "simulate(\"infectious\", 0.1, 0.1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dropdown = widgets.Dropdown(options=['infectious', 'ht09_contact', 'SFHH', 'tij_InVS15'], description='Dataset', disabled=False, continuous_update=True)\n",
    "phi_slider = widgets.FloatSlider(min=0.1, max=0.9, step=0.01, value=0.1, continuous_update=True)\n",
    "delta_t_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.1, continuous_update=True)\n",
    "beta_slider = widgets.FloatSlider(min=0, max=1, step=0.01, value=0.75, continuous_update=True)\n",
    "\n",
    "w = widgets.interactive(simulate, dataset=dataset_dropdown.value, delta_t=delta_t_slider.value, phi=phi_slider.value, beta=beta_slider.value)\n",
    "display(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e35c14a8caca76198b34fb255762891fb38351c0ec24f1fa8546521f6a1a9596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
